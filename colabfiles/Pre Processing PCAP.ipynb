{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11805,"status":"ok","timestamp":1711030775908,"user":{"displayName":"Arun Savio","userId":"00138333015975321945"},"user_tz":-330},"id":"WgyuD3-pXsPl","outputId":"021118ce-c8e9-4f97-dee2-f28ca44fc5ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting scapy\n","  Downloading scapy-2.5.0.tar.gz (1.3 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.3 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: scapy\n","  Building wheel for scapy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for scapy: filename=scapy-2.5.0-py2.py3-none-any.whl size=1444327 sha256=33418bc5ddfef997469d59d733a4d069f01afb1bb466083b7e88e021e7084f8a\n","  Stored in directory: /root/.cache/pip/wheels/82/b7/03/8344d8cf6695624746311bc0d389e9d05535ca83c35f90241d\n","Successfully built scapy\n","Installing collected packages: scapy\n","Successfully installed scapy-2.5.0\n"]}],"source":["!pip install scapy\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16248,"status":"ok","timestamp":1711030808852,"user":{"displayName":"Arun Savio","userId":"00138333015975321945"},"user_tz":-330},"id":"6dye6YSmX-tr","outputId":"7d363cf0-de9d-4f80-aa74-356c83f21822"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":351094,"status":"ok","timestamp":1711031246931,"user":{"displayName":"Arun Savio","userId":"00138333015975321945"},"user_tz":-330},"id":"eOTm3SM9X-we","outputId":"b6f57d13-ae0c-45a5-9269-b960ad52a656"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting rarfile\n","  Downloading rarfile-4.1-py3-none-any.whl (28 kB)\n","Installing collected packages: rarfile\n","Successfully installed rarfile-4.1\n","Extraction complete. Files are in: /content/extracted/\n"]}],"source":["!pip install rarfile\n","\n","import rarfile\n","\n","# Path to the RAR file\n","rar_file_path = '/content/drive/MyDrive/Caida 2007/labeled_ddostrace.to-victim.20070804 sep Fastest.rar'\n","\n","# Destination directory for extraction\n","extracted_directory = '/content/extracted/'\n","\n","# Create the destination directory if it doesn't exist\n","import os\n","os.makedirs(extracted_directory, exist_ok=True)\n","\n","# Open the RAR file\n","with rarfile.RarFile(rar_file_path, 'r') as rar:\n","    # Extract all files to the destination directory\n","    rar.extractall(extracted_directory)\n","\n","print(f\"Extraction complete. Files are in: {extracted_directory}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1711031246931,"user":{"displayName":"Arun Savio","userId":"00138333015975321945"},"user_tz":-330},"id":"URA9CKUuX-1T","outputId":"5b1bb337-bd40-457a-c55e-640d3d8b25b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["ddostrace.to-victim.20070804_145436.pcap  drive  extracted  sample_data\n"]}],"source":["!cd /content/extracted\n","!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"GGxMqg0LX-3h","outputId":"ceef82d8-22e7-41bb-b07b-1fd1d9a3bfd4"},"outputs":[{"name":"stderr","output_type":"stream","text":["Splitting ddostrace.to-victim.20070804_145436.pcap: 2450013 packets [26:56, 1516.05 packets/s]\n"]},{"name":"stdout","output_type":"stream","text":["Split ddostrace.to-victim.20070804_145436.pcap into 15 parts successfully.\n"]}],"source":["from scapy.all import *\n","import os\n","from tqdm import tqdm\n","\n","def split_pcap(input_file):\n","    # Create a directory to store the cropped pcap files if it doesn't exist\n","    if not os.path.exists(\"cropped\"):\n","        os.makedirs(\"cropped\")\n","\n","    # Get the base name of the input file\n","    base_name = os.path.splitext(os.path.basename(input_file))[0]\n","\n","    # Define the time interval (5 seconds)\n","    interval = 1\n","\n","    # Initialize variables for file index and packet count\n","    file_index = 1\n","    packet_count = 0\n","\n","    # Open the pcap file in read mode\n","    with PcapReader(input_file) as pcap_reader:\n","        # Initialize tqdm progress bar\n","        progress_bar = tqdm(desc=f\"Splitting {input_file}\", unit=\" packets\")\n","\n","        # Initialize list to store packets for the current interval\n","        interval_packets = []\n","\n","        # Loop through each packet in the pcap file\n","        for packet in pcap_reader:\n","            # Calculate the elapsed time since the start of the capture\n","            elapsed_time = packet.time - interval_packets[0].time if interval_packets else 0\n","\n","            # Check if elapsed time exceeds the interval\n","            if elapsed_time >= interval:\n","                # Write the interval packets to a new pcap file\n","                output_file = f\"cropped/{base_name}_{file_index}.pcap\"\n","                wrpcap(output_file, interval_packets)\n","\n","                # Reset variables for the next interval\n","                interval_packets = [packet]\n","                file_index += 1\n","            else:\n","                # Add the packet to the current interval\n","                interval_packets.append(packet)\n","\n","            # Increment packet count\n","            packet_count += 1\n","\n","            # Update the progress bar\n","            progress_bar.update(1)\n","\n","        # Close the progress bar\n","        progress_bar.close()\n","\n","    print(f\"Split {input_file} into {file_index} parts successfully.\")\n","\n","# Get a list of all .pcap files in the current directory\n","pcap_files = [f for f in os.listdir() if f.endswith('.pcap')]\n","\n","# Iterate over each .pcap file and split it\n","for pcap_file in pcap_files:\n","    split_pcap(pcap_file)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3lACDv3xZOJF"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"metadata":{"id":"pmO3C-vzZOMD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711034043308,"user_tz":-330,"elapsed":843851,"user":{"displayName":"Arun Savio","userId":"00138333015975321945"}},"outputId":"db209152-50e3-4a84-cb3c-a6176f0a641d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Processing ddostrace.to-victim.20070804_145436_12.pcap...\n","Features extracted and saved to ddostrace.to-victim.20070804_145436_12.csv\n","Processing ddostrace.to-victim.20070804_145436_3.pcap...\n","Features extracted and saved to ddostrace.to-victim.20070804_145436_3.csv\n","Processing ddostrace.to-victim.20070804_145436_8.pcap...\n","Features extracted and saved to ddostrace.to-victim.20070804_145436_8.csv\n","Processing ddostrace.to-victim.20070804_145436_6.pcap...\n","Features extracted and saved to ddostrace.to-victim.20070804_145436_6.csv\n","Processing ddostrace.to-victim.20070804_145436_10.pcap...\n","Features extracted and saved to ddostrace.to-victim.20070804_145436_10.csv\n","Processing ddostrace.to-victim.20070804_145436_11.pcap...\n","Features extracted and saved to ddostrace.to-victim.20070804_145436_11.csv\n","Processing ddostrace.to-victim.20070804_145436_2.pcap...\n","Features extracted and saved to ddostrace.to-victim.20070804_145436_2.csv\n","Processing ddostrace.to-victim.20070804_145436_13.pcap...\n","Features extracted and saved to ddostrace.to-victim.20070804_145436_13.csv\n","Processing ddostrace.to-victim.20070804_145436_14.pcap...\n","Features extracted and saved to ddostrace.to-victim.20070804_145436_14.csv\n","Processing ddostrace.to-victim.20070804_145436_4.pcap...\n","Features extracted and saved to ddostrace.to-victim.20070804_145436_4.csv\n","Processing ddostrace.to-victim.20070804_145436_9.pcap...\n","Features extracted and saved to ddostrace.to-victim.20070804_145436_9.csv\n","Processing ddostrace.to-victim.20070804_145436_1.pcap...\n","Features extracted and saved to ddostrace.to-victim.20070804_145436_1.csv\n","Processing ddostrace.to-victim.20070804_145436_7.pcap...\n","Features extracted and saved to ddostrace.to-victim.20070804_145436_7.csv\n","Processing ddostrace.to-victim.20070804_145436_5.pcap...\n","Features extracted and saved to ddostrace.to-victim.20070804_145436_5.csv\n"]}],"source":["from scapy.all import *\n","import pandas as pd\n","import os\n","from math import log2\n","\n","# Function to calculate entropy\n","def calculate_entropy(data):\n","    entropy = 0\n","    total_count = len(data)\n","    value_counts = data.value_counts()\n","    for count in value_counts:\n","        probability = count / total_count\n","        entropy -= probability * log2(probability)\n","    return entropy\n","\n","# Function to extract features from pcap file\n","def extract_features_from_pcap(pcap_file):\n","    packets = rdpcap('/content/cropped/'+pcap_file)\n","\n","    # Initialize lists to store extracted features\n","    src_ips = []\n","    src_ports = []\n","    dst_ports = []\n","    packet_protocols = []\n","    total_packets = len(packets)\n","\n","    # Extract features from each packet\n","    for packet in packets:\n","        if IP in packet:\n","            src_ips.append(packet[IP].src)\n","            if packet.haslayer(TCP) or packet.haslayer(UDP):\n","                src_ports.append(packet[IP].sport)\n","                dst_ports.append(packet[IP].dport)\n","            else:\n","                src_ports.append(None)\n","                dst_ports.append(None)\n","            packet_protocols.append(packet[IP].proto)\n","\n","    # Calculate entropies\n","    etpSrcIP = calculate_entropy(pd.Series(src_ips))\n","    etpSrcP = calculate_entropy(pd.Series(src_ports))\n","    etpDstP = calculate_entropy(pd.Series(dst_ports))\n","    etpProtocol = calculate_entropy(pd.Series(packet_protocols))\n","\n","    return {\n","        'etpSrcIP': etpSrcIP,\n","        'etpSrcP': etpSrcP,\n","        'etpDstP': etpDstP,\n","        'etpProtocol': etpProtocol,\n","        'totalPacket': total_packets\n","    }\n","\n","# Iterate over pcap files in the directory\n","pcap_files = [file for file in os.listdir(\"/content/cropped\") if file.endswith('.pcap')]\n","for pcap_file in pcap_files:\n","    print(f'Processing {pcap_file}...')\n","    features = extract_features_from_pcap(pcap_file)\n","    filename = os.path.splitext(pcap_file)[0] + '.csv'\n","    pd.DataFrame([features]).to_csv(filename, index=False)\n","    print(f'Features extracted and saved to {filename}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a_pPn2uBZORy"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Bt6rz1sdZOWt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711034272598,"user_tz":-330,"elapsed":534,"user":{"displayName":"Arun Savio","userId":"00138333015975321945"}},"outputId":"ccc53fb1-b83b-4018-a3be-9afd9ec5f8c2"},"outputs":[{"output_type":"stream","name":"stdout","text":["    etpSrcIP   etpSrcP   etpDstP  etpProtocol  totalPacket\n","0  11.908531  1.158816  0.748006     0.358235       170458\n","All CSV files combined into 'combined.csv'.\n"]}],"source":["import os\n","import pandas as pd\n","\n","def combine_csv_files():\n","    # Get the current directory\n","    current_directory = os.getcwd()\n","\n","    # List all files in the current directory\n","    files = os.listdir(current_directory)\n","\n","    # Filter out only CSV files\n","    csv_files = [file for file in files if file.endswith('.csv')]\n","\n","    if not csv_files:\n","        print(\"No CSV files found in the current directory.\")\n","        return\n","\n","    # Read the first CSV file to get the column names\n","    first_file = csv_files[0]\n","    df_combined = pd.read_csv(first_file)\n","    print(df_combined)\n","    # Combine all CSV files\n","    for file in csv_files[1:]:\n","        df = pd.read_csv(file)\n","        df_combined = pd.concat([df_combined, df], ignore_index=True)\n","\n","    # Write the combined dataframe to a new CSV file\n","    combined_filename = \"combined.csv\"\n","    df_combined.to_csv(combined_filename, index=False)\n","\n","    print(f\"All CSV files combined into '{combined_filename}'.\")\n","\n","if __name__ == \"__main__\":\n","    combine_csv_files()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j9b-VfPeZOZa"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6tDYrGvnZOcV"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eCwF6vzWZOfF"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cW13II5xZOh8"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wHD5P6xJZOl8"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1dZndDBNPCemglfkoOVTUuV8oIdZSF4j0","authorship_tag":"ABX9TyOFomyzvciZpHufbhVdat3Z"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}